---
title: "Homework 2"
author: "Henry Stoddard"
date: "9/24/2020"
output: github_document
---
## Problem 1

Importing Mr Trash Wheel dataset and tidying 

```{r library, import, tidy}
library(tidyverse)
library(readxl)
trash_df = read_excel("./data/Mr_Trash_Wheel.xlsx")
trash_df = janitor::clean_names(trash_df) %>% select(-notes, -x16, -x17) %>% drop_na(dumpster) %>% mutate(sports_balls = round(sports_balls), sports_balls = as.integer(sports_balls))
```

Importing and tidying precipitation datasets
```{r precipitation}
precip2018_df = read_excel("./data/Mr_Trash_Wheel.xlsx", sheet = "2018 Precipitation", skip = 1) %>% janitor::clean_names() %>% drop_na(month) %>% mutate(year = 2018) %>% relocate(year)

precip2017_df = read_excel("./data/Mr_Trash_Wheel.xlsx", sheet = "2017 Precipitation", skip = 1) %>% janitor::clean_names() %>% drop_na(month) %>% mutate(year = 2017) %>% relocate(year)
```

Now combining datasets
```{r merge}
precip_df = bind_rows(precip2018_df, precip2017_df) %>% mutate(month = month.name[month])
```
```{r specific analysis}
sum(pull(precip2018_df, total)) %>% view()
balls_df = select(trash_df, sports_balls, year)
balls2017_df = subset(balls_df, year == 2017) %>%summarise_if(is.numeric, na.rm = TRUE, median) %>% view()
```


## Data Summary
These two datasets include info from the Mr. Trashwheel collector in Baltimore, MD. This machine collects trash and then stores it in a dumpster. Data includes info on year, month, trash collected, and the amounts of some specific kinds of trash. There are a total of `r nrow(trash_df)` rows in our final dataset. Additional data sheets include precipitation data by month and year, which have a total of `r nrow(precip_df)` rows. In 2018, there was a total of `r sum(pull(precip2018_df, total))` inches of rain. In 2017, the median number of sports balls in a dumpster was 8.

## Problem 2
Importing, cleaning, and transforming the NYC transit data

```{r import2}
nyc_df = read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% janitor::clean_names() %>% select(line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, entrance_type, ada) %>% mutate(entry = recode(entry, YES = TRUE, NO = FALSE))
summary(nyc_df)
```
### data summary
This dataset contains information on NYC subway entrances and exits, including the location, line, latitude and longitude, ADA accessibility, and other information. So far, names have been tidied, some variables were dropped, and entry was recoded from yes/no to true/false. This dataset has 1868 rows and 19 columns. The data are reasonably tidy, but not as tidy as they could be.

### additional analyses
```{r analysis2}
distinct(nyc_df, station_name, line)
summary(pull(nyc_df, ada))
nyc2_df = select(nyc_df, entry, vending) %>% subset(vending =="NO")
sum(pull(nyc2_df, entry))
```

There are 465 distinct stations. 468 Stations are ADA compliant. Out of the 183 stations without vending, 69 (`r (69/183)*100`%) allow entry.

Now reformating so that route number and name are distinct variables. Then, making that dataframe only include stations that serve the A train, so that we can find the distinct number of stations that serve the A train. Finally, finding out how many of the stations serving the A train are ADA compliant.
```{r reformat}
nyc_df3 = nyc_df %>% 
  mutate(route8 = as.character(route8),
       route9 = as.character(route9),
       route10 = as.character(route10),
       route11 = as.character(route11)) %>% pivot_longer(route1:route11, names_to = "route", names_prefix = "route", values_to = "route_name") 
nyc_df3 = subset(nyc_df3, route_name == "A")
nyc_df4 = distinct(nyc_df3, station_name, line)
summary(pull(nyc_df3, ada))
```
There are `r nrow(nyc_df4)` distinct stations that serve the A train. 107 stations that serve the A train are ADA compliant.

## Question 3
Importing political dataset, cleaning, separating date into day month and year, replacing month number with name, creating president var which tells political party, and dropping a few variables that are no longer needed.
```{r}
pols_df = read_csv("./data/pols-month.csv") %>% janitor::clean_names() %>% separate(mon, into = c("year", "month", "day"), convert = TRUE) %>% mutate(month = recode(month, `01` = "January", `02` = "February", `03` = "March", `04` = "April", `05` = "May", `06` = "June", `07` = "July", `08` = "August", `09` = "September", `10` = "October", `11` = "November", `12` = "December")) %>% mutate(president = ifelse(prez_gop == 1, "gop", "dem")) %>% select(-prez_dem, -prez_gop, -day) %>% arrange(year, match(month, month.name))
```

Now importing snp.csv, cleaning, arranging according to year and month, converting month to character
```{r}
snp_df = read_csv("./data/snp.csv") %>% janitor::clean_names() %>% separate(date, into = c("month", "day", "year"), convert = TRUE) %>% select(-day) %>% relocate("year", "month", "close") %>% mutate(month = recode(month, `01` = "January", `02` = "February", `03` = "March", `04` = "April", `05` = "May", `06` = "June", `07` = "July", `08` = "August", `09` = "September", `10` = "October", `11` = "November", `12` = "December"))%>% arrange(year, match(month, month.name))
```

Now importing unemployment data, cleaning names, and using pivot_longer to get unemployed rate by month.
```{r}
une_df = read_csv("./data/unemployment.csv") %>% janitor::clean_names() %>% pivot_longer(jan:dec, names_to = "month", values_to = "unemployed_rate") %>% mutate(month = recode(month, "jan" = "January", "feb" = "February", "mar" = "March", "apr" = "April", "may" = "May", "jun" = "June", "jul" = "July", "aug" = "August", "sep" = "September", "oct" = "October", "nov" = "November", "dec" = "December")) %>% arrange(year, match(month, month.name))
```

Now joining all three datasets:
```{r}
final_df = full_join(pols_df, snp_df, by = c("month", "year"))
final_df2 = full_join(final_df, une_df, by = c("month", "year"))
```
This final dataset is a combination of three smaller datasets. The pols_df dataset contains political information by month and year, including the number of governors, senators, representatives and presidents by political party. The snp_df dataset contains stock market data, showing the closing value of the SnP 500 by month and year. Finally, the une_df dataset contains unemployment data by month and year.
The resulting dataset, final_df2, is 828 rows long by 11 columns wide. It includes data from 1947 through 2015. Key variables include the number of governors, senators, representatives and presidents by political party, closing value of the SnP 500, and unemployment rate by month and year.
