Homework 2
================
Henry Stoddard
9/24/2020

## Problem 1

Importing Mr Trash Wheel dataset and tidying

``` r
library(tidyverse)
```

    ## -- Attaching packages ------------------------ tidyverse 1.3.0 --

    ## v ggplot2 3.3.2     v purrr   0.3.4
    ## v tibble  3.0.3     v dplyr   1.0.1
    ## v tidyr   1.1.1     v stringr 1.4.0
    ## v readr   1.3.1     v forcats 0.5.0

    ## -- Conflicts --------------------------- tidyverse_conflicts() --
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
trash_df = read_excel("./data/Mr_Trash_Wheel.xlsx")
```

    ## New names:
    ## * `` -> ...16
    ## * `` -> ...17

``` r
trash_df = janitor::clean_names(trash_df) %>% select(-notes, -x16, -x17) %>% drop_na(dumpster) %>% mutate(sports_balls = round(sports_balls), sports_balls = as.integer(sports_balls))
```

Importing and tidying precipitation datasets

``` r
precip2018_df = read_excel("./data/Mr_Trash_Wheel.xlsx", sheet = "2018 Precipitation", skip = 1) %>% janitor::clean_names() %>% drop_na(month) %>% mutate(year = 2018) %>% relocate(year)

precip2017_df = read_excel("./data/Mr_Trash_Wheel.xlsx", sheet = "2017 Precipitation", skip = 1) %>% janitor::clean_names() %>% drop_na(month) %>% mutate(year = 2017) %>% relocate(year)
```

Now combining datasets

``` r
precip_df = bind_rows(precip2018_df, precip2017_df) %>% mutate(month = month.name[month])
```

``` r
sum(pull(precip2018_df, total)) %>% view()
balls_df = select(trash_df, sports_balls, year)
balls2017_df = subset(balls_df, year == 2017) %>%summarise_if(is.numeric, na.rm = TRUE, median) %>% view()
```

## Data Summary

These two datasets include info from the Mr.Â Trashwheel collector in
Baltimore, MD. This machine collects trash and then stores it in a
dumpster. Data includes info on year, month, trash collected, and the
amounts of some specific kinds of trash. There are a total of 344 rows
in our final dataset. Additional data sheets include precipitation data
by month and year, which have a total of 24 rows. In 2018, there was a
total of 70.33 inches of rain. In 2017, the median number of sports
balls in a dumpster was 8.

## Problem 2

Importing, cleaning, and transforming the NYC transit data

``` r
nyc_df = read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% janitor::clean_names() %>% select(line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, entrance_type, ada) %>% mutate(entry = recode(entry, YES = TRUE, NO = FALSE))
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

``` r
summary(nyc_df)
```

    ##      line           station_name       station_latitude station_longitude
    ##  Length:1868        Length:1868        Min.   :40.58    Min.   :-74.03   
    ##  Class :character   Class :character   1st Qu.:40.69    1st Qu.:-73.99   
    ##  Mode  :character   Mode  :character   Median :40.73    Median :-73.96   
    ##                                        Mean   :40.73    Mean   :-73.94   
    ##                                        3rd Qu.:40.77    3rd Qu.:-73.91   
    ##                                        Max.   :40.90    Max.   :-73.76   
    ##                                                                          
    ##     route1             route2             route3             route4         
    ##  Length:1868        Length:1868        Length:1868        Length:1868       
    ##  Class :character   Class :character   Class :character   Class :character  
    ##  Mode  :character   Mode  :character   Mode  :character   Mode  :character  
    ##                                                                             
    ##                                                                             
    ##                                                                             
    ##                                                                             
    ##     route5             route6             route7              route8     
    ##  Length:1868        Length:1868        Length:1868        Min.   :1.000  
    ##  Class :character   Class :character   Class :character   1st Qu.:1.000  
    ##  Mode  :character   Mode  :character   Mode  :character   Median :4.000  
    ##                                                           Mean   :2.979  
    ##                                                           3rd Qu.:5.000  
    ##                                                           Max.   :5.000  
    ##                                                           NA's   :1820   
    ##      route9         route10        route11       entry        
    ##  Min.   :2.000   Min.   :3      Min.   :7      Mode :logical  
    ##  1st Qu.:2.000   1st Qu.:3      1st Qu.:7      FALSE:115      
    ##  Median :2.000   Median :3      Median :7      TRUE :1753     
    ##  Mean   :2.536   Mean   :3      Mean   :7                     
    ##  3rd Qu.:2.000   3rd Qu.:3      3rd Qu.:7                     
    ##  Max.   :5.000   Max.   :3      Max.   :7                     
    ##  NA's   :1840    NA's   :1845   NA's   :1845                  
    ##    vending          entrance_type         ada         
    ##  Length:1868        Length:1868        Mode :logical  
    ##  Class :character   Class :character   FALSE:1400     
    ##  Mode  :character   Mode  :character   TRUE :468      
    ##                                                       
    ##                                                       
    ##                                                       
    ## 

### data summary

This dataset contains information on NYC subway entrances and exits,
including the location, line, latitude and longitude, ADA accessibility,
and other information. So far, names have been tidied, some variables
were dropped, and entry was recoded from yes/no to true/false. This
dataset has 1868 rows and 19 columns. The data are reasonably tidy, but
not as tidy as they could be.

### additional analyses

``` r
distinct(nyc_df, station_name, line)
```

    ## # A tibble: 465 x 2
    ##    line     station_name            
    ##    <chr>    <chr>                   
    ##  1 4 Avenue 25th St                 
    ##  2 4 Avenue 36th St                 
    ##  3 4 Avenue 45th St                 
    ##  4 4 Avenue 53rd St                 
    ##  5 4 Avenue 59th St                 
    ##  6 4 Avenue 77th St                 
    ##  7 4 Avenue 86th St                 
    ##  8 4 Avenue 95th St                 
    ##  9 4 Avenue 9th St                  
    ## 10 4 Avenue Atlantic Av-Barclays Ctr
    ## # ... with 455 more rows

``` r
summary(pull(nyc_df, ada))
```

    ##    Mode   FALSE    TRUE 
    ## logical    1400     468

``` r
nyc2_df = select(nyc_df, entry, vending) %>% subset(vending =="NO")
sum(pull(nyc2_df, entry))
```

    ## [1] 69

There are 465 distinct stations. 468 Stations are ADA compliant. Out of
the 183 stations without vending, 69 (37.704918%) allow entry.

Now reformating so that route number and name are distinct variables.
Then, making that dataframe only include stations that serve the A
train, so that we can find the distinct number of stations that serve
the A train. Finally, finding out how many of the stations serving the A
train are ADA compliant.

``` r
nyc_df3 = nyc_df %>% 
  mutate(route8 = as.character(route8),
       route9 = as.character(route9),
       route10 = as.character(route10),
       route11 = as.character(route11)) %>% pivot_longer(route1:route11, names_to = "route", names_prefix = "route", values_to = "route_name") 
nyc_df3 = subset(nyc_df3, route_name == "A")
nyc_df4 = distinct(nyc_df3, station_name, line)
summary(pull(nyc_df3, ada))
```

    ##    Mode   FALSE    TRUE 
    ## logical     166     107

There are 60 distinct stations that serve the A train. 107 stations that
serve the A train are ADA compliant.

## Question 3

Importing political dataset, cleaning, separating date into day month
and year, replacing month number with name, creating president var which
tells political party, and dropping a few variables that are no longer
needed.

``` r
pols_df = read_csv("./data/pols-month.csv") %>% janitor::clean_names() %>% separate(mon, into = c("year", "month", "day"), convert = TRUE) %>% mutate(month = recode(month, `01` = "January", `02` = "February", `03` = "March", `04` = "April", `05` = "May", `06` = "June", `07` = "July", `08` = "August", `09` = "September", `10` = "October", `11` = "November", `12` = "December")) %>% mutate(president = ifelse(prez_gop == 1, "gop", "dem")) %>% select(-prez_dem, -prez_gop, -day) %>% arrange(year, match(month, month.name))
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

Now importing snp.csv, cleaning, arranging according to year and month,
converting month to character

``` r
snp_df = read_csv("./data/snp.csv") %>% janitor::clean_names() %>% separate(date, into = c("month", "day", "year"), convert = TRUE) %>% select(-day) %>% relocate("year", "month", "close") %>% mutate(month = recode(month, `01` = "January", `02` = "February", `03` = "March", `04` = "April", `05` = "May", `06` = "June", `07` = "July", `08` = "August", `09` = "September", `10` = "October", `11` = "November", `12` = "December"))%>% arrange(year, match(month, month.name))
```

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

Now importing unemployment data, cleaning names, and using pivot\_longer
to get unemployed rate by month.

``` r
une_df = read_csv("./data/unemployment.csv") %>% janitor::clean_names() %>% pivot_longer(jan:dec, names_to = "month", values_to = "unemployed_rate") %>% mutate(month = recode(month, "jan" = "January", "feb" = "February", "mar" = "March", "apr" = "April", "may" = "May", "jun" = "June", "jul" = "July", "aug" = "August", "sep" = "September", "oct" = "October", "nov" = "November", "dec" = "December")) %>% arrange(year, match(month, month.name))
```

    ## Parsed with column specification:
    ## cols(
    ##   Year = col_double(),
    ##   Jan = col_double(),
    ##   Feb = col_double(),
    ##   Mar = col_double(),
    ##   Apr = col_double(),
    ##   May = col_double(),
    ##   Jun = col_double(),
    ##   Jul = col_double(),
    ##   Aug = col_double(),
    ##   Sep = col_double(),
    ##   Oct = col_double(),
    ##   Nov = col_double(),
    ##   Dec = col_double()
    ## )

Now joining all three datasets:

``` r
final_df = full_join(pols_df, snp_df, by = c("month", "year"))
final_df2 = full_join(final_df, une_df, by = c("month", "year"))
```

This final dataset is a combination of three smaller datasets. The
pols\_df dataset contains political information by month and year,
including the number of governors, senators, representatives and
presidents by political party. The snp\_df dataset contains stock market
data, showing the closing value of the SnP 500 by month and year.
Finally, the une\_df dataset contains unemployment data by month and
year. The resulting dataset, final\_df2, is 828 rows long by 11 columns
wide. It includes data from 1947 through 2015. Key variables include the
number of governors, senators, representatives and presidents by
political party, closing value of the SnP 500, and unemployment rate by
month and year.
